Hierachical clustering is a method of cluster analysis which falls into two types:
Agglomerative: Here, each data point starts as cluster and pairs up clusters as we go up the hierarchy.
Divisive: The entire data set is considered a cluster and breaks down as we move down the hierarchy.
This exercise explores three amonng the many variants of agglomerative hierarchical clustering based on the distance metric used.
Single-Link
Complete-Link
Mean-Link 
code : hierarchy.py


Point Assignment Clustering
    In Point Assignment based clustering, every point is assigned to a cluster center based on a distance metric. 
In this exercise we discuss two types of these clusters:
 Gonzalez (1895)
   Gonzalez algorithm is a faster k-center clustering method. Although k-center clustering is NP hard, Gonzalez uses a factor 2 approximation and is quite fast. The main principle is greedily pick a point in the dataset furthest from the current set of center and add it to the list of centers.
code: gonzalez.py

 K-Means++
   K-Means++ is similar to Gonzalez except that it is not completely greedy. 
code: kMeansPlus.py

 Lloyds Algorithm
   Lloyds Algorithm starts with k point sites and alternates between two steps:
   Assignment step: Assign each observation to the cluster which has the "nearest" mean. 
   Update step: Calculate the new means to be the centroids of the observations in the new clusters.
code: lloyd.py

K-Median Clustering
It is a variation of k-means clustering in which instead of calculating mean for each cluster, we calculate the median. 
code: kMedian.py

source: wikipedia

